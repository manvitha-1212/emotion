{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os,sys\n%matplotlib inline\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Input, Flatten, Dropout, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\nfrom IPython.display import SVG, Image\n\nfrom tensorflow.keras.models import Sequential\n ","metadata":{"execution":{"iopub.status.busy":"2021-06-10T15:34:36.260116Z","iopub.execute_input":"2021-06-10T15:34:36.260843Z","iopub.status.idle":"2021-06-10T15:34:41.921694Z","shell.execute_reply.started":"2021-06-10T15:34:36.260798Z","shell.execute_reply":"2021-06-10T15:34:41.920712Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dir=os.listdir(\"../input/emotion-detection-fer\")\nfor expression in dir:\n     print(expression);","metadata":{"execution":{"iopub.status.busy":"2021-06-10T15:34:44.187945Z","iopub.execute_input":"2021-06-10T15:34:44.188375Z","iopub.status.idle":"2021-06-10T15:34:44.208853Z","shell.execute_reply.started":"2021-06-10T15:34:44.188345Z","shell.execute_reply":"2021-06-10T15:34:44.207661Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"test\ntrain\n","output_type":"stream"}]},{"cell_type":"code","source":"img_size=48\nbatch_size=64\ndata_train=ImageDataGenerator(horizontal_flip=True)\ntrain=data_train.flow_from_directory(\"../input/emotion-detection-fer/train\",target_size=\n(48,48), batch_size=batch_size, class_mode='categorical', shuffle=True)\n\ndatagen_validation=ImageDataGenerator(horizontal_flip=True)\n\ntest=datagen_validation.flow_from_directory(\"../input/emotion-detection-fer/test\",target_size=\n(48,48), batch_size=batch_size, class_mode='categorical', shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T15:34:45.635652Z","iopub.execute_input":"2021-06-10T15:34:45.636016Z","iopub.status.idle":"2021-06-10T15:35:25.381491Z","shell.execute_reply.started":"2021-06-10T15:34:45.635988Z","shell.execute_reply":"2021-06-10T15:35:25.380088Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 28709 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model=Sequential()\n#conv-1\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape= (48,48,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#conv-2\nmodel.add(Conv2D(128,(5,5), padding='same', input_shape= (48,48,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#conv-3\nmodel.add(Conv2D(512,(3,3), padding='same', input_shape= (48,48,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#conv-4\nmodel.add(Conv2D(512,(3,3), padding='same', input_shape= (48,48,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#conv-5\nmodel.add(Conv2D(512,(3,3), padding='same', input_shape= (48,48,3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))\nopt=Adam(lr=0.0005)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T15:35:27.698802Z","iopub.execute_input":"2021-06-10T15:35:27.699147Z","iopub.status.idle":"2021-06-10T15:35:30.361844Z","shell.execute_reply.started":"2021-06-10T15:35:27.699094Z","shell.execute_reply":"2021-06-10T15:35:30.360745Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T15:35:36.727171Z","iopub.execute_input":"2021-06-10T15:35:36.727544Z","iopub.status.idle":"2021-06-10T15:35:36.773568Z","shell.execute_reply.started":"2021-06-10T15:35:36.727512Z","shell.execute_reply":"2021-06-10T15:35:36.772484Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 48, 48, 64)        1792      \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 48, 48, 64)        256       \n_________________________________________________________________\nactivation (Activation)      (None, 48, 48, 64)        0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 24, 24, 128)       0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 12, 12, 512)       590336    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 12, 12, 512)       2048      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 12, 12, 512)       0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n_________________________________________________________________\nactivation_3 (Activation)    (None, 6, 6, 512)         0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 3, 3, 512)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 3, 3, 512)         2048      \n_________________________________________________________________\nactivation_4 (Activation)    (None, 3, 3, 512)         0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1, 1, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               131328    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 256)               1024      \n_________________________________________________________________\nactivation_5 (Activation)    (None, 256)               0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               131584    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 512)               2048      \n_________________________________________________________________\nactivation_6 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 3591      \n=================================================================\nTotal params: 5,793,159\nTrainable params: 5,788,167\nNon-trainable params: 4,992\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs=50\nsteps_per_epoch=train.n//train.batch_size\nsteps_per_epoch\nvalidation_steps=train.n//test.batch_size\n\n\nhistory= model.fit(x=train,steps_per_epoch=steps_per_epoch,epochs=epochs,validation_data=test,validation_steps=validation_steps)\n\n#saving the model\nmodel.save('emotion.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T15:35:38.123936Z","iopub.execute_input":"2021-06-10T15:35:38.124382Z","iopub.status.idle":"2021-06-10T16:03:37.463204Z","shell.execute_reply.started":"2021-06-10T15:35:38.124349Z","shell.execute_reply":"2021-06-10T16:03:37.462016Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/50\n448/448 [==============================] - 262s 572ms/step - loss: 2.0082 - accuracy: 0.2259 - val_loss: 2.0723 - val_accuracy: 0.2562\nEpoch 2/50\n448/448 [==============================] - 28s 63ms/step - loss: 1.5870 - accuracy: 0.3890\nEpoch 3/50\n448/448 [==============================] - 28s 62ms/step - loss: 1.3971 - accuracy: 0.4607\nEpoch 4/50\n448/448 [==============================] - 28s 62ms/step - loss: 1.2895 - accuracy: 0.5068\nEpoch 5/50\n448/448 [==============================] - 28s 62ms/step - loss: 1.2288 - accuracy: 0.5303\nEpoch 6/50\n448/448 [==============================] - 28s 62ms/step - loss: 1.1675 - accuracy: 0.5601\nEpoch 7/50\n448/448 [==============================] - 28s 63ms/step - loss: 1.1356 - accuracy: 0.5651\nEpoch 8/50\n448/448 [==============================] - 29s 64ms/step - loss: 1.1043 - accuracy: 0.5781\nEpoch 9/50\n448/448 [==============================] - 28s 62ms/step - loss: 1.0795 - accuracy: 0.5972\nEpoch 10/50\n448/448 [==============================] - 28s 63ms/step - loss: 1.0577 - accuracy: 0.5992\nEpoch 11/50\n448/448 [==============================] - 28s 63ms/step - loss: 1.0315 - accuracy: 0.6064\nEpoch 12/50\n448/448 [==============================] - 28s 62ms/step - loss: 1.0021 - accuracy: 0.6218\nEpoch 13/50\n448/448 [==============================] - 28s 64ms/step - loss: 0.9796 - accuracy: 0.6312\nEpoch 14/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.9578 - accuracy: 0.6419\nEpoch 15/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.9420 - accuracy: 0.6484\nEpoch 16/50\n448/448 [==============================] - 28s 63ms/step - loss: 0.9050 - accuracy: 0.6571\nEpoch 17/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.8943 - accuracy: 0.6654\nEpoch 18/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.8723 - accuracy: 0.6756\nEpoch 19/50\n448/448 [==============================] - 29s 66ms/step - loss: 0.8483 - accuracy: 0.6833\nEpoch 20/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.8303 - accuracy: 0.6896\nEpoch 21/50\n448/448 [==============================] - 29s 66ms/step - loss: 0.8082 - accuracy: 0.7003\nEpoch 22/50\n448/448 [==============================] - 31s 70ms/step - loss: 0.7868 - accuracy: 0.7073\nEpoch 23/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.7751 - accuracy: 0.7067\nEpoch 24/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.7507 - accuracy: 0.7211\nEpoch 25/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.7254 - accuracy: 0.7310\nEpoch 26/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.7039 - accuracy: 0.7367\nEpoch 27/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.6849 - accuracy: 0.7480\nEpoch 28/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.6643 - accuracy: 0.7548\nEpoch 29/50\n448/448 [==============================] - 30s 66ms/step - loss: 0.6474 - accuracy: 0.7612\nEpoch 30/50\n448/448 [==============================] - 30s 68ms/step - loss: 0.6439 - accuracy: 0.7634\nEpoch 31/50\n448/448 [==============================] - 30s 67ms/step - loss: 0.6313 - accuracy: 0.7636\nEpoch 32/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.5902 - accuracy: 0.7768\nEpoch 33/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.5591 - accuracy: 0.7918\nEpoch 34/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.5574 - accuracy: 0.7956\nEpoch 35/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.5502 - accuracy: 0.7991\nEpoch 36/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.5262 - accuracy: 0.8089\nEpoch 37/50\n448/448 [==============================] - 28s 63ms/step - loss: 0.5132 - accuracy: 0.8128\nEpoch 38/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.4950 - accuracy: 0.8195\nEpoch 39/50\n448/448 [==============================] - 29s 66ms/step - loss: 0.4765 - accuracy: 0.8247\nEpoch 40/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.4721 - accuracy: 0.8257\nEpoch 41/50\n448/448 [==============================] - 30s 67ms/step - loss: 0.4633 - accuracy: 0.8306\nEpoch 42/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.4455 - accuracy: 0.8341\nEpoch 43/50\n448/448 [==============================] - 28s 64ms/step - loss: 0.4241 - accuracy: 0.8440\nEpoch 44/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.4148 - accuracy: 0.8454\nEpoch 45/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.4112 - accuracy: 0.8476\nEpoch 46/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.3877 - accuracy: 0.8568\nEpoch 47/50\n448/448 [==============================] - 29s 64ms/step - loss: 0.3826 - accuracy: 0.8591\nEpoch 48/50\n448/448 [==============================] - 28s 63ms/step - loss: 0.3792 - accuracy: 0.8640\nEpoch 49/50\n448/448 [==============================] - 29s 65ms/step - loss: 0.3672 - accuracy: 0.8672\nEpoch 50/50\n448/448 [==============================] - 29s 66ms/step - loss: 0.3456 - accuracy: 0.8753\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}